/**
 * Edge AI Service - Supabase Edge Functions ile AI API √ßaƒürƒ±larƒ±
 * API key'leri server tarafƒ±nda tutar, g√ºvenli API √ßaƒürƒ±larƒ± yapar
 */
import { supabase } from '@/lib/supabase';
import * as FileSystem from 'expo-file-system';

export interface AnalysisRequest {
  text: string;
  userId: string;
  analysisType?: 'voice' | 'data' | 'mixed';
  context?: {
    source: 'today' | 'mood' | 'tracking' | 'cbt';
    timestamp?: number;
    metadata?: any;
  };
}

export interface UnifiedAnalysisResult {
  category: 'MOOD' | 'CBT' | 'OCD' | 'ERP' | 'BREATHWORK' | 'UNKNOWN';
  confidence: number;
  summary: string;
  suggestions: string[];
  insights: {
    cbt?: {
      automaticThought: string;
      cognitiveDistortions: string[];
      evidenceFor: string[];
      evidenceAgainst: string[];
      balancedThought: string;
      mood: number;
    };
    mood?: {
      detectedMood: string;
      intensity: number;
      triggers: string[];
      suggestions: string[];
    };
    ocd?: {
      obsession: string;
      compulsion: string;
      avoidance: string[];
      erpSuggestion: string;
    };
    breathwork?: {
      technique: string;
      duration: number;
      benefits: string[];
    };
  };
  metadata?: {
    modelUsed: string;
    processingTime: number;
    timestamp: string;
  };
}

export interface EdgeAIResponse {
  success: boolean;
  result?: UnifiedAnalysisResult;
  error?: string;
  message?: string;
}

/**
 * Edge AI Service Class
 */
class EdgeAIService {
  private static instance: EdgeAIService;
  private readonly FUNCTION_NAME = 'analyze-voice';

  private constructor() {}

  static getInstance(): EdgeAIService {
    if (!EdgeAIService.instance) {
      EdgeAIService.instance = new EdgeAIService();
    }
    return EdgeAIService.instance;
  }

  /**
   * Supabase Edge Function ile ses analizi yapar
   */
  async analyzeText(request: AnalysisRequest): Promise<UnifiedAnalysisResult | null> {
    try {
      // Supabase auth session kontrol√º
      const { data: { session } } = await supabase.auth.getSession();
      if (!session) {
        console.error('EdgeAIService: No active session found');
        return null;
      }

      const { data, error } = await supabase.functions.invoke<EdgeAIResponse>(
        this.FUNCTION_NAME,
        {
          body: request,
        }
      );

      if (error) {
        console.error('EdgeAIService: Function invocation error:', error);
        return null;
      }

      if (!data?.success || !data.result) {
        console.error('EdgeAIService: Invalid response:', data);
        return null;
      }

      return data.result;

    } catch (error) {
      console.error('EdgeAIService: Unexpected error:', error);
      return null;
    }
  }

  /**
   * Ses giri≈üi i√ßin √∂zel analiz fonksiyonu 
   * checkinService.ts'teki unifiedVoiceAnalysis ile uyumlu
   */
  async analyzeVoiceInput(
    text: string, 
    userId: string,
    context?: {
      source: 'today' | 'mood' | 'tracking' | 'cbt';
      timestamp?: number;
      metadata?: any;
    }
  ): Promise<UnifiedAnalysisResult | null> {
    return this.analyzeText({
      text,
      userId,
      analysisType: 'voice',
      context: {
        source: 'today',
        timestamp: Date.now(),
        ...context
      }
    });
  }

  /**
   * Metin verisi analizi
   */
  async analyzeDataInput(
    text: string, 
    userId: string,
    context?: {
      source: 'today' | 'mood' | 'tracking' | 'cbt';
      timestamp?: number;
      metadata?: any;
    }
  ): Promise<UnifiedAnalysisResult | null> {
    return this.analyzeText({
      text,
      userId,
      analysisType: 'data',
      context: {
        source: 'tracking',
        timestamp: Date.now(),
        ...context
      }
    });
  }

  /**
   * CBT analizi i√ßin √∂zel fonksiyon
   */
  async analyzeCBTInput(
    text: string,
    userId: string,
    metadata?: any
  ): Promise<UnifiedAnalysisResult | null> {
    return this.analyzeText({
      text,
      userId,
      analysisType: 'mixed',
      context: {
        source: 'cbt',
        timestamp: Date.now(),
        metadata
      }
    });
  }

  /**
   * Health check - Edge function'ƒ±n √ßalƒ±≈üƒ±p √ßalƒ±≈ümadƒ±ƒüƒ±nƒ± kontrol eder
   */
  async healthCheck(): Promise<boolean> {
    try {
      // Simple session check instead of full API call (avoid circular dependency)
      const { data: { session } } = await supabase.auth.getSession();
      if (!session) {
        console.log('EdgeAIService: No active session - health check failed');
        return false;
      }
      
      // If we have a session, assume edge function is available
      // Full function test would create circular dependency with ExternalAIService
      console.log('EdgeAIService: Session active - health check passed');
      return true;
    } catch (error) {
      console.error('EdgeAIService: Health check failed:', error);
      return false;
    }
  }

  /**
   * Batch analiz - birden fazla metni aynƒ± anda analiz eder
   */
  async batchAnalyze(
    requests: AnalysisRequest[]
  ): Promise<(UnifiedAnalysisResult | null)[]> {
    const promises = requests.map(request => this.analyzeText(request));
    return Promise.all(promises);
  }

  /**
   * Ses dosyasƒ± analizi - STT + Gemini pipeline 
   * YENƒ∞: Storage-based yakla≈üƒ±m - b√ºy√ºk dosyalar i√ßin
   */
  async analyzeAudioViaStorage(
    audioUri: string,
    userId: string,
    languageCode: string = 'tr-TR',
    context?: {
      source: 'today' | 'mood' | 'tracking' | 'cbt';
      timestamp?: number;
      metadata?: any;
    }
  ): Promise<UnifiedAnalysisResult | null> {
    try {
      // Supabase auth session kontrol√º
      const { data: { session } } = await supabase.auth.getSession();
      if (!session) {
        console.error('EdgeAIService: No active session found for storage upload');
        return null;
      }

      console.log('üì§ Starting Storage-based audio analysis...');

      // 0. Bucket check devre dƒ±≈üƒ± (RLS policy sorunu)
      console.log('üìã Skipping bucket creation (will be created manually)');

      // 1. Audio dosyasƒ±nƒ± Supabase Storage'a upload et
      const fileName = `voice-${userId.substring(0, 8)}-${Date.now()}.wav`;
      
      // Audio dosyasƒ±nƒ± blob olarak oku
      const audioBlob = await fetch(audioUri).then(r => r.blob());
      
      const { data: uploadData, error: uploadError } = await supabase.storage
        .from('audio-temp')
        .upload(fileName, audioBlob, {
          contentType: 'audio/wav',
          cacheControl: '3600',
          upsert: false
        });

      if (uploadError) {
        console.error('‚ùå Storage upload failed:', uploadError);
        return null;
      }

      console.log('‚úÖ Audio uploaded to storage:', fileName);

      // 2. Edge Function'a Storage URL g√∂nder (base64 deƒüil!)
      const { data, error } = await supabase.functions.invoke<{
        success: boolean;
        result?: UnifiedAnalysisResult;
        error?: string;
      }>('analyze-audio-storage', {
        body: {
          audioPath: uploadData.path,
          userId,
          languageCode,
          analysisType: 'voice',
          context: {
            source: 'today',
            timestamp: Date.now(),
            ...context
          }
        }
      });

      // 3. Temp dosyayƒ± sil
      setTimeout(async () => {
        await supabase.storage.from('audio-temp').remove([fileName]);
        console.log('üóëÔ∏è Temp audio file cleaned up');
      }, 5000);

      if (error) {
        console.error('EdgeAIService: Storage-based analysis error:', error);
        return null;
      }

      if (!data?.success || !data.result) {
        console.error('EdgeAIService: Invalid storage analysis response:', data);
        return null;
      }

      console.log('‚úÖ Storage-based audio analysis completed');
      return data.result;

    } catch (error) {
      console.error('EdgeAIService: Storage analysis unexpected error:', error);
      return null;
    }
  }

  /**
   * Ses dosyasƒ± analizi - STT + Gemini pipeline 
   * ESKƒ∞: Direct base64 yakla≈üƒ±m - k√º√ß√ºk dosyalar i√ßin
   */
  async analyzeAudio(
    audioUri: string,
    userId: string,
    languageCode: string = 'tr-TR',
    context?: {
      source: 'today' | 'mood' | 'tracking' | 'cbt';
      timestamp?: number;
      metadata?: any;
    }
  ): Promise<UnifiedAnalysisResult | null> {
    try {
      // Supabase auth session kontrol√º
      const { data: { session } } = await supabase.auth.getSession();
      if (!session) {
        console.error('EdgeAIService: No active session found for audio analysis');
        return null;
      }

      console.log('üéµ Starting secure audio analysis pipeline...');

      // Audio dosyasƒ±nƒ± base64'e √ßevir
      const audioBase64 = await FileSystem.readAsStringAsync(audioUri, {
        encoding: FileSystem.EncodingType.Base64,
      });

      console.log(`üìÅ Audio file converted to base64 (${audioBase64.length} chars)`);

      // Edge Function √ßaƒürƒ±sƒ± - b√ºy√ºk audio dosyalarƒ± i√ßin timeout artƒ±rdƒ±k
      const { data, error } = await supabase.functions.invoke<{
        success: boolean;
        result?: UnifiedAnalysisResult;
        error?: string;
      }>('analyze-audio', {
        body: {
          audioBase64,
          userId,
          languageCode,
          analysisType: 'voice',
          context: {
            source: 'today',
            timestamp: Date.now(),
            ...context
          }
        },
        headers: {
          'Content-Type': 'application/json',
          'X-Client-Info': 'obsessless-mobile'
        }
      });

      if (error) {
        const errorDetails = {
          error: error,
          message: error.message,
          cause: error.cause,
          audioSize: audioBase64.length,
          userId: userId.substring(0, 8) + '...'
        };
        
        console.error('EdgeAIService: Audio analysis error details:', errorDetails);
        
        // Specific error handling for audio size
        if (audioBase64.length > 500 * 1024) {
          console.warn(`üö® Audio too large for Edge Function: ${audioBase64.length} chars (max: ${500 * 1024})`);
          console.log('üí° Suggestion: WAV format needs more space, but 3 seconds should work');
        }
        
        return null;
      }

      if (!data?.success || !data.result) {
        console.error('EdgeAIService: Invalid audio analysis response:', data);
        return null;
      }

      console.log('‚úÖ Secure audio analysis completed:', {
        category: data.result.category,
        confidence: data.result.confidence,
        sttSuccess: !data.result.metadata?.sttFailed,
        transcribedText: data.result.metadata?.transcribedText?.substring(0, 50) + '...'
      });

      return data.result;

    } catch (error) {
      console.error('EdgeAIService: Audio analysis unexpected error:', error);
      return null;
    }
  }
}

// Singleton instance
export const edgeAIService = EdgeAIService.getInstance();

// Backward compatibility - checkinService.ts i√ßin
export default edgeAIService;
